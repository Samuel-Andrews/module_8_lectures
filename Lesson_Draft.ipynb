{
 "cells": [
  {
   "source": [
    "### Object Detection"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Object the detection in the realm of image processing is the process by which an image or video is taken, and elements within it are uniquley identified. In theory, it can be used on any class of objects with shared conceptual features, but in practice it works best on highly detailed strucutres.\n",
    "\n",
    "By far, the most common example is the human face, such as seen below."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#insert face here"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "Given an image such as this, we can idenify unique aspects presented in the image through the use of a Haar based cascade clasifier. More specifically, one can use a more powerful boosted variant that takes a machine learning approach similar to classificaiton problems you may have seen in DSCI 425.\n",
    "\n",
    "\n",
    "At its core, the classifier is ultimatley just a prediction model that has been trained extensively on images that do and do not contain the object we wish to detect. A powerful advantage of opencv's implentation is that many such classifiers have already been put togther, saving us the trouble of needed to tackle a prediction problem before we start the actual implementation. However, if you were to use for something more niche, you may need to build a clasifier yourself.\n",
    "\n",
    "Many of the most commononly used classifiers can be found on the official github paige: https://github.com/opencv/opencv/tree/master/data/haarcascades\n",
    "\n",
    "Simply download the .xml of your choosing and place it in your working directory."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##insert relevant image here"
   ]
  },
  {
   "source": [
    "As for how the classifiers work in specific, they analyze positive cases looking for edge features in each image by subtracting the sum of pixels in different proportions of pieces of the image to extract Haar features (shown below)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##insert Haar iamge types here"
   ]
  },
  {
   "source": [
    "While this way of analysis on its own would be more then sufficent in a vaccuum, higher resolution images will quickly inflate the number of times one must perform this strategy to levels beyond human practicality. Numerous attempts over the years to make this more efficent have come and gone, but ultimatley a process has been settled on that appears to maxmimize its efficeny.\n",
    "\n",
    "How and why we arrived at this manner is beyond the scope of this lesson, but whats is important is a simple understanding of the solution: Cascading\n",
    "\n",
    "After processing the training data looking for features, those which are deemed relevant and effective are tossed and only useful ones remain. Keep in mind, it is usually a variety of hundreds or thousands of small features that together are able to make the distinction rather then a single predictor.\n",
    "\n",
    "This predictors are then categorized into various sequential groups and placed in a hieracrhy of importance within each group.\n",
    "\n",
    "Now, when a new image is fed to this classifier, it is run through the first group of feature tests, if it fails to many of them at any point, it is discarded at that point. If at any point in any group, it passes enoguh tests, it is immediatly placed into the next group and the process continues. There tends to be fewer features in the first stages, with amounts getting bigger the more stages there are. This allows for quick removal of negative cases and a more quickly confirmed positive"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##insert cascading image here"
   ]
  },
  {
   "source": [
    "An example implementation on our face is seen below:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##import the classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read image in"
   ]
  },
  {
   "source": [
    "To keep our features consistant across envoirnments and to elimnate a variable to complicated for us to accuratley measure, image detection almost always uses grayscaled images."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conver to grayscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#detect faces"
   ]
  },
  {
   "source": [
    "Running our classifier, it appears to have found the face. We can vizualize what it has found using Matplotlib"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display face with box"
   ]
  },
  {
   "source": [
    "We can also look for more specific items as well. Now that we have a partition of just a face, perhaps we want to single out the eyes. To do that, we can simply run another classifier on are now smaller area and search for them directly.\n",
    "\n",
    "While we could also do this on the whole image, we should be more likely to get an accurate result if we first remove background images more likely to contain features the training data did not account for."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eye example"
   ]
  },
  {
   "source": [
    "This is all well and good, but it may also seem rather trivial. All we have done is identify a face and two eyes. A child could do that. However, the speed of the algorithm and its ability to classify passivly does lend itself well to solveing a number of kinds of problems."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "For example, say you have an image of a crowd of individuals, and you want to be able to tell how many people are in it without counting heads yourself. Due to this classifier being able to find multiple faces in a single image, you could simply run this detecter again on that image and return a count of the number of faces found.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#crowdcount example"
   ]
  },
  {
   "source": [
    "This can be incredibly useful to venue planners that lack other ways of tracking attendence of certain events that do not do direct ticket sales, such as public ampitheaters, poltical events, and religous gatherings. Furthermore, there is could also be used on more commercail gatherings such as sporting events and traditional theather were the sale of tickets may not truly correlate to the number of people who actually show up.\n",
    "\n",
    "The ability to map a crowd also allows to analyze another feature as well. Previously, we have shown the ability to pick out details such as eyes within a face, but we can go beyond that into the realm of variable collection. For example, we could pull out the number of smiles these individuals have as a way to track sentiment, and by taking picture (or using real-time video) over the course of an event we would be able to tie a number to how many people enjoyed what they were seeing.\n",
    "\n",
    "Of course, this comes with all of the same (and more) caveats sentiment analysis has, but is something worth exploring. An example of such is shown below."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##smiling crowd example"
   ]
  },
  {
   "source": [
    "This utility is not just regulated to big problems though, as even a common individual may find usage in everyday tasks.\n",
    "\n",
    "For instance, perhaps you are a cat owner who desires a pet door that will allow your cat, or any others you host, to enter and exit your enclosed backyard whenever they please, but you wouldn't want a rodent, bird, or large insect to use it. You could place a motion sensitve camera near the door that takes a picture of those outside of the door that checks to see if a cat is directly outside of it before opening. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#cat example"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "Or, perhaps you have a large collection of images from trail camera and you want to see how many times they were triggered by animals that are not human. You could run them all through a classifier and remove images that contain a human body, rather than an entire face."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of images that may or may not contain a human body example."
   ]
  },
  {
   "source": [
    "### Further Notes\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Everything explained and shown above can also be applied to real-time video as well at the expense of computational power and the time taken to implement, however jupyter notebooks tend to struggle with implementing such. For more information, see opencv's official documentation on the matter here: https://docs.opencv.org/4.4.0/db/d28/tutorial_cascade_classifier.html \n",
    "\n",
    "\n",
    "This allows it to tackle a larger variety of problems and perform more accurate results in many cases, and is the kind one is more likely to see in many practical implementations. The principal the same, just that every problem becomes a list problem and the speed of classification must be considered more closely.\n",
    "\n",
    "Image detection also paves the way for image recognition, which allows for unique objects, such as faces, to act as recognizable keys that allow for convienant and easy to use for securing everday devices from phones to even cars. However, certain uses of facial recognition have proven controverstial in recent history.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### References\n",
    "\n",
    "Object Detection Algorithm:\n",
    "\n",
    "https://www.cs.cmu.edu/~efros/courses/LBMV07/Papers/viola-cvpr-01.pdf\n",
    "\n",
    "Implementation:\n",
    "\n",
    "https://docs.opencv.org/4.4.0/d2/d64/tutorial_table_of_content_objdetect.html\n",
    "\n",
    "Cascaded Classifer visual:\n",
    "\n",
    "https://www.researchgate.net/figure/An-example-of-a-cascading-classifier-for-classifying-image-element-as-pedestrian_fig4_331727963\n",
    "\n",
    "Facial Recongition contraversy:\n",
    "\n",
    "https://www.nytimes.com/2019/05/15/business/facial-recognition-software-controversy.html\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Singular face\n",
    "\n",
    "crowdcount\n",
    "\n",
    "Images that may or may not contain a cat\n",
    "\n",
    "Smiling faces in crowd\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}